{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for A...\n",
      "Fetching data for AA...\n",
      "Fetching data for AAL...\n",
      "Fetching data for AAMI...\n",
      "Fetching data for AAOI...\n",
      "Fetching data for AAON...\n",
      "Fetching data for AAP...\n",
      "Fetching data for AAPL...\n",
      "Fetching data for AAT...\n",
      "Fetching data for AAWW...\n",
      "Fetching data for ABAX...\n",
      "Fetching data for ABBV...\n",
      "Fetching data for ABCB...\n",
      "Fetching data for ABG...\n",
      "Fetching data for ABM...\n",
      "Fetching data for ABMD...\n",
      "Fetching data for ABNB...\n",
      "Fetching data for ABR...\n",
      "Fetching data for ABT...\n",
      "Fetching data for ABX...\n",
      "No data found for ABX\n",
      "Fetching data for ACA...\n",
      "Fetching data for ACAT...\n",
      "Fetching data for ACGL...\n",
      "Fetching data for ACHC...\n",
      "Fetching data for ACIC...\n",
      "Fetching data for ACIW...\n",
      "Fetching data for ACLS...\n",
      "Fetching data for ACM...\n",
      "Fetching data for ACN...\n",
      "Fetching data for ADBE...\n",
      "Fetching data for ADC...\n",
      "Fetching data for ADEA...\n",
      "Fetching data for ADI...\n",
      "Fetching data for ADM...\n",
      "Fetching data for ADMA...\n",
      "Fetching data for ADNT...\n",
      "Fetching data for ADP...\n",
      "Fetching data for ADSK...\n",
      "Fetching data for ADTN...\n",
      "Fetching data for ADUS...\n",
      "Fetching data for ADVS...\n",
      "Fetching data for AEE...\n",
      "Fetching data for AEGN...\n",
      "Fetching data for AEIS...\n",
      "Fetching data for AEL...\n",
      "Fetching data for AEO...\n",
      "Fetching data for AEP...\n",
      "Fetching data for AES...\n",
      "Fetching data for AESC...\n",
      "Fetching data for AESI...\n",
      "Fetching data for AET...\n",
      "Fetching data for AFAM...\n",
      "Fetching data for AFFX...\n",
      "Fetching data for AFG...\n",
      "Fetching data for AFL...\n",
      "Fetching data for AGCO...\n",
      "Fetching data for AGN...\n",
      "Fetching data for AGO...\n",
      "Fetching data for AGYS...\n",
      "Fetching data for AHCO...\n",
      "Fetching data for AHH...\n",
      "Fetching data for AIG...\n",
      "Fetching data for AIN...\n",
      "Fetching data for AIR...\n",
      "Fetching data for AIRM...\n",
      "Fetching data for AIT...\n",
      "Fetching data for AIV...\n",
      "Fetching data for AIZ...\n",
      "Fetching data for AJG...\n",
      "Fetching data for AJRD...\n",
      "Fetching data for AKAM...\n",
      "Fetching data for AKR...\n",
      "Fetching data for AKS...\n",
      "Fetching data for AL...\n",
      "Fetching data for ALB...\n",
      "Fetching data for ALE...\n",
      "Fetching data for ALEX...\n",
      "Fetching data for ALG...\n",
      "Fetching data for ALGM...\n",
      "Fetching data for ALGN...\n",
      "Fetching data for ALGT...\n",
      "Fetching data for ALK...\n",
      "Fetching data for ALKS...\n",
      "Fetching data for ALL...\n",
      "Fetching data for ALLE...\n",
      "Fetching data for ALLY...\n",
      "Fetching data for ALOG...\n",
      "Fetching data for ALRM...\n",
      "Fetching data for ALTM...\n",
      "Fetching data for ALTR...\n",
      "Fetching data for ALV...\n",
      "Fetching data for ALXN...\n",
      "Fetching data for AM...\n",
      "Fetching data for AMAG...\n",
      "Fetching data for AMAT...\n",
      "Fetching data for AMBC...\n",
      "Fetching data for AMCC...\n",
      "Fetching data for AMCR...\n",
      "Fetching data for AMCX...\n",
      "Fetching data for AMD...\n",
      "Fetching data for AME...\n",
      "Fetching data for AMED...\n",
      "Fetching data for AMG...\n",
      "Fetching data for AMGN...\n",
      "Fetching data for AMH...\n",
      "Fetching data for AMKR...\n",
      "Fetching data for AMN...\n",
      "Fetching data for AMP...\n",
      "Fetching data for AMPH...\n",
      "Fetching data for AMR...\n",
      "Fetching data for AMSF...\n",
      "Fetching data for AMT...\n",
      "Fetching data for AMTM...\n",
      "Fetching data for AMWD...\n",
      "Fetching data for AMZN...\n",
      "Fetching data for AN...\n",
      "Fetching data for ANDE...\n",
      "Fetching data for ANDV...\n",
      "Fetching data for ANET...\n",
      "Fetching data for ANF...\n",
      "Fetching data for ANGO...\n",
      "Fetching data for ANIK...\n",
      "Fetching data for ANIP...\n",
      "Fetching data for ANN...\n",
      "Fetching data for ANSS...\n",
      "Fetching data for AOL...\n",
      "Fetching data for AON...\n",
      "Fetching data for AORT...\n",
      "Fetching data for AOS...\n",
      "Fetching data for AOSL...\n",
      "Fetching data for APA...\n",
      "Fetching data for APAM...\n",
      "Fetching data for APC...\n",
      "Fetching data for APD...\n",
      "Fetching data for APEI...\n",
      "Fetching data for APH...\n",
      "Fetching data for APLE...\n",
      "Fetching data for APO...\n",
      "Fetching data for APOG...\n",
      "Fetching data for APOL...\n",
      "Fetching data for APPF...\n",
      "Fetching data for APTV...\n",
      "Fetching data for AR...\n",
      "Fetching data for ARCB...\n",
      "Fetching data for ARCH...\n",
      "Fetching data for ARE...\n",
      "Fetching data for ARG...\n",
      "Fetching data for ARI...\n",
      "Fetching data for ARLO...\n",
      "Fetching data for ARMK...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "\n",
    "# File path for tickers\n",
    "TICKERS_FILE = r\"C:\\Users\\Jrans\\Desktop\\Model Comparison Project\\Data\\unique_tickers.csv\"\n",
    "\n",
    "# Output file path for combined CSV\n",
    "OUTPUT_FILE = r\"C:\\Users\\Jrans\\Desktop\\Model Comparison Project\\Data\\all_tickers_monthly_data.csv\"\n",
    "\n",
    "# Read tickers from CSV, ensuring to exclude the header and correctly parse tickers\n",
    "tickers = pd.read_csv(TICKERS_FILE, usecols=[\"Ticker\"], dtype=str).dropna().squeeze().unique()\n",
    "\n",
    "# API URL\n",
    "API_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "# Date range filter\n",
    "START_DATE = \"1995-01-01\"\n",
    "END_DATE = \"2025-01-01\"\n",
    "\n",
    "def fetch_monthly_data(ticker):\n",
    "    \"\"\"Fetch monthly adjusted price data from Alpha Vantage API.\"\"\"\n",
    "    params = {\n",
    "        \"function\": \"TIME_SERIES_MONTHLY_ADJUSTED\",\n",
    "        \"symbol\": ticker,\n",
    "        \"apikey\": API_KEY,\n",
    "        \"datatype\": \"json\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(API_URL, params=params)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    if \"Monthly Adjusted Time Series\" not in data:\n",
    "        print(f\"No data found for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert JSON to DataFrame\n",
    "    df = pd.DataFrame.from_dict(data[\"Monthly Adjusted Time Series\"], orient=\"index\")\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    df.columns = [\n",
    "        \"open\", \"high\", \"low\", \"close\", \"adjusted_close\", \"volume\", \"dividend\"\n",
    "    ]\n",
    "    \n",
    "    # Convert index to datetime\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    \n",
    "    # Convert columns to numeric\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    \n",
    "    # Filter data within date range\n",
    "    df = df[(df.index >= START_DATE) & (df.index <= END_DATE)]\n",
    "    \n",
    "    # Reset index to make \"date\" a column\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "    \n",
    "    # Add ticker column\n",
    "    df[\"ticker\"] = ticker\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Initialize an empty list to store data\n",
    "all_data = []\n",
    "\n",
    "# Fetch and append data for each ticker\n",
    "for ticker in tickers:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    df = fetch_monthly_data(ticker)\n",
    "    \n",
    "    if df is not None:\n",
    "        all_data.append(df)\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Save to a single CSV file\n",
    "    combined_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"All tickers' data saved to {OUTPUT_FILE}\")\n",
    "else:\n",
    "    print(\"No data was retrieved.\")\n",
    "\n",
    "print(\"Data collection complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
